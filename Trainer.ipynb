{
 "cells": [
  {
   "cell_type": "code",
   "id": "423bfed44c2b7742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:25:51.843380Z",
     "start_time": "2025-05-29T20:25:51.834450Z"
    }
   },
   "source": [
    "from jedi.inference.utils import to_list\n",
    "\n",
    "# read it in to inspect it\n",
    "with open ('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# print(\"the length of the array is: \", len(text))\n",
    "# print(text[:1000])\n"
   ],
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:25:51.982279Z",
     "start_time": "2025-05-29T20:25:51.970866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#all the characters that occur in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)\n"
   ],
   "id": "d8538d05af4c8cca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:25:52.015833Z",
     "start_time": "2025-05-29T20:25:52.009822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create a mapping for characters to integers\n",
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "# print(encode(\"hii there\"))\n",
    "# print(decode(encode(\"hii there\")))\n"
   ],
   "id": "f85728622409bf78",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:25:52.138626Z",
     "start_time": "2025-05-29T20:25:52.030531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch  # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])  # the 1000 characters we looked at earlier will to the GPT look like this\n",
    "\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n"
   ],
   "id": "bf87fe597ab19624",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:25:52.155067Z",
     "start_time": "2025-05-29T20:25:52.150485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ],
   "id": "d8480ddd94f37796",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:25:52.181455Z",
     "start_time": "2025-05-29T20:25:52.176347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "print(x,y)\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ],
   "id": "ec9ced34e231417a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:25:52.204276Z",
     "start_time": "2025-05-29T20:25:52.197268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 4  # how many independent sequences will we process in parallel?\n",
    "block_size = 8  # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # if for example len is 30 it generates numbers in [0, 22); [0,21]\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # if 21 is generated [21: 29) in other words [21: 28]\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]) # if 21 is generated [22: 30) in other words [22: 29]\n",
    "    return x, y\n",
    "# \n",
    "xb, yb = get_batch('train')\n",
    "# # print('inputs  :') \n",
    "# # print(xb.shape)\n",
    "# # print(xb)\n",
    "# # print('targets:')\n",
    "# # print(yb.shape)\n",
    "# # print(yb)\n",
    "\n",
    "print('----')\n",
    "for b in range(batch_size):  # batch dimension\n",
    "    for t in range(block_size):  # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "when input is [56] the target: 57\n",
      "when input is [56, 57] the target: 43\n",
      "when input is [56, 57, 43] the target: 57\n",
      "when input is [56, 57, 43, 57] the target: 1\n",
      "when input is [56, 57, 43, 57, 1] the target: 47\n",
      "when input is [56, 57, 43, 57, 1, 47] the target: 52\n",
      "when input is [56, 57, 43, 57, 1, 47, 52] the target: 1\n",
      "when input is [56, 57, 43, 57, 1, 47, 52, 1] the target: 46\n",
      "when input is [43] the target: 56\n",
      "when input is [43, 56] the target: 63\n",
      "when input is [43, 56, 63] the target: 1\n",
      "when input is [43, 56, 63, 1] the target: 46\n",
      "when input is [43, 56, 63, 1, 46] the target: 39\n",
      "when input is [43, 56, 63, 1, 46, 39] the target: 42\n",
      "when input is [43, 56, 63, 1, 46, 39, 42] the target: 1\n",
      "when input is [43, 56, 63, 1, 46, 39, 42, 1] the target: 57\n",
      "when input is [42] the target: 43\n",
      "when input is [42, 43] the target: 0\n",
      "when input is [42, 43, 0] the target: 13\n",
      "when input is [42, 43, 0, 13] the target: 1\n",
      "when input is [42, 43, 0, 13, 1] the target: 51\n",
      "when input is [42, 43, 0, 13, 1, 51] the target: 47\n",
      "when input is [42, 43, 0, 13, 1, 51, 47] the target: 57\n",
      "when input is [42, 43, 0, 13, 1, 51, 47, 57] the target: 43\n",
      "when input is [43] the target: 63\n",
      "when input is [43, 63] the target: 1\n",
      "when input is [43, 63, 1] the target: 51\n",
      "when input is [43, 63, 1, 51] the target: 47\n",
      "when input is [43, 63, 1, 51, 47] the target: 45\n",
      "when input is [43, 63, 1, 51, 47, 45] the target: 46\n",
      "when input is [43, 63, 1, 51, 47, 45, 46] the target: 58\n",
      "when input is [43, 63, 1, 51, 47, 45, 46, 58] the target: 1\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:25:52.236705Z",
     "start_time": "2025-05-29T20:25:52.220154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) \n",
    "\n",
    "    def forward(self, idx, targets=None ): # This function receives B by T tensor of elements \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx)  # (B,T,C)\n",
    "    \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else: #when no target is defined this else is not run therefore the dimensionality of logits will not change\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets  = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is B by T array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:] # now it becomes B by C since we only plucked out the last row of each batch \n",
    "            probs = F.softmax(logits, dim=-1) # also B by C; one probability per each class for all batches\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #one suggestion to be added to the last element of each batch\n",
    "            idx = torch.cat((idx, idx_next), dim=-1)\n",
    "        return idx\n",
    "            \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "# [0] is because the nature of the m.generate output is still a 2D tensor and the elements in the first row are called using the row index and the column index, so if we want to have the whole row together we need to use [0]\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long),max_new_tokens=100)[0].tolist()))"
   ],
   "id": "a4a30e3492201b03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8513, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:25:52.327565Z",
     "start_time": "2025-05-29T20:25:52.324194Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)",
   "id": "b5a291e18c0955b8",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:30:46.842967Z",
     "start_time": "2025-05-29T20:28:08.671191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "for _ in range(100000):\n",
    "    # here we are sampling data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # here we evaluate the loss and optimize using gradients\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "print(loss.item())\n",
    "    \n",
    "    "
   ],
   "id": "105d5d7d76208801",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.385108232498169\n"
     ]
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:10.694136Z",
     "start_time": "2025-05-29T20:31:10.556173Z"
    }
   },
   "cell_type": "code",
   "source": "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long),max_new_tokens=1000)[0].tolist()))\n",
   "id": "9deeeeded37c9b01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Haye oathawee\n",
      "Whathiesovenn n wio.\n",
      "LABom TES:\n",
      "HAntouged derisly;\n",
      "INES:\n",
      "PO wiowado s at lfe. wigoan l t whedanthebe winor 'd.\n",
      "Card as ooracollt, thes\n",
      "se wo mane y wond.\n",
      "INGRI s GELit. forofedeat s frgss,\n",
      "K:\n",
      "Hal t t; fo n.\n",
      "'sourmonem o wh wef thoy au, her land ges urndom howhugary wassucavom? The me d,\n",
      "RG adoueentand ourk fre Ifot su we t.\n",
      "NTENGeh, trde assenjoche t bos, swar heonas thintousear!\n",
      "HELem:\n",
      "Gotheret\n",
      "LELUS:\n",
      "TE kig f s CHo shene posed ather anjor'st prs d I iry,\n",
      "To ourd toth muric t Is s nean chonicasersie I cct bllllediap, f se,\n",
      "ISOManne s,\n",
      "INI ABurdighy ha---pl be dvethens oth r per. me thot:\n",
      "A:\n",
      "\n",
      "N g htint aderesed oud tilfrt au then:\n",
      "Cornngs n ghonth, aiere I s,\n",
      "Sis y d h GLoway cer ther. t, m'tunow, gou'diny ABEDate cut, fis\n",
      "ad k to,\n",
      "An's he--phepthist thof linghe, s wan, th t th ol e pat Lar the thounfra w, ft thethe.\n",
      "Heronk'e st hag there t ims he.\n",
      "Bueeeret s this, suile for t ild.\n",
      "Alle dro ddif t\n",
      "ERKIZE t I pe corsord'th grmemy,\n",
      "PEDYCARDUCLAPons pavepothon pllanceit wa\n"
     ]
    }
   ],
   "execution_count": 152
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
